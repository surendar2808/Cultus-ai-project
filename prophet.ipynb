{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsNAGePGzu2m"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Advanced Time Series Forecasting with Prophet and Optuna\n",
        "File: prophet_optuna_pipeline.py\n",
        "\n",
        "This script generates a synthetic multi-seasonal time series (3+ years daily),\n",
        "implements walk-forward cross-validation, builds a baseline Prophet model,\n",
        "optimizes hyperparameters using Optuna, trains a final optimized Prophet model,\n",
        "compares it with an Exponential Smoothing baseline, and outputs forecast values\n",
        "for the held-out test period.\n",
        "\n",
        "Usage:\n",
        "    python prophet_optuna_pipeline.py\n",
        "\n",
        "Requirements:\n",
        "    pip install prophet optuna statsmodels pandas numpy scikit-learn matplotlib\n",
        "\n",
        "Notes:\n",
        "- This code is intended for educational / research use. For production, adapt\n",
        "  data-loading, logging, and model persistence to your environment.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Prophet import with fallback\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "except Exception:\n",
        "    try:\n",
        "        from fbprophet import Prophet\n",
        "    except Exception as e:\n",
        "        raise ImportError(\n",
        "            \"Prophet is not installed. Install with `pip install prophet` or `pip install fbprophet`.\"\n",
        "        )\n",
        "\n",
        "import optuna\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# 1) DATA GENERATION\n",
        "# -----------------------------\n",
        "\n",
        "def generate_synthetic_daily(start_date=\"2016-01-01\",\n",
        "                             end_date=\"2020-12-31\",\n",
        "                             seed=42,\n",
        "                             trend_slope=0.0007,\n",
        "                             yearly_strength=30,\n",
        "                             weekly_strength=7,\n",
        "                             noise_std=3.0):\n",
        "    \"\"\"Generate synthetic daily time series with trend, yearly and weekly seasonalities.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    start_date : str\n",
        "        Start date (inclusive) in YYYY-MM-DD\n",
        "    end_date : str\n",
        "        End date (inclusive) in YYYY-MM-DD\n",
        "    seed : int\n",
        "        Random seed\n",
        "    trend_slope : float\n",
        "        Linear trend slope applied to the scaled time index\n",
        "    yearly_strength : float\n",
        "        Amplitude of yearly seasonality\n",
        "    weekly_strength : float\n",
        "        Amplitude of weekly seasonality\n",
        "    noise_std : float\n",
        "        Standard deviation of Gaussian noise\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame with columns ['ds', 'y'] suitable for Prophet\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    idx = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "    n = len(idx)\n",
        "\n",
        "    t = np.arange(n) / n\n",
        "    # Linear trend\n",
        "    trend = trend_slope * np.arange(n)\n",
        "\n",
        "    # Yearly seasonality (using a simple cosine with period ~365)\n",
        "    day_of_year = idx.dayofyear - 1\n",
        "    yearly = yearly_strength * np.cos(2 * np.pi * day_of_year / 365.25)\n",
        "\n",
        "    # Weekly seasonality\n",
        "    dow = idx.dayofweek\n",
        "    weekly = weekly_strength * np.where(dow < 5, 1.0, 0.3)  # weekdays higher\n",
        "    weekly = weekly * np.sin(2 * np.pi * dow / 7)\n",
        "\n",
        "    # Add some occasional holiday spikes\n",
        "    holiday_effect = np.zeros(n)\n",
        "    # Synthetic holidays: pick ~6 random dates per year to add a bump\n",
        "    years = np.unique(idx.year)\n",
        "    for y in years:\n",
        "        rng = np.random.default_rng(seed + int(y))\n",
        "        picks = rng.choice(pd.date_range(start=f\"{y}-01-01\", end=f\"{y}-12-31\", freq='D').values,\n",
        "                           size=6, replace=False)\n",
        "        for p in picks:\n",
        "            p = pd.to_datetime(p)\n",
        "            loc = np.where(idx == p)[0]\n",
        "            if len(loc) > 0:\n",
        "                holiday_effect[loc[0]] += rng.normal(15, 5)\n",
        "\n",
        "    noise = np.random.normal(0, noise_std, size=n)\n",
        "\n",
        "    y = 100 + 10 * trend + yearly + weekly + holiday_effect + noise\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'ds': idx,\n",
        "        'y': y\n",
        "    })\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2) WALK-FORWARD CROSS-VALIDATION UTILITIES\n",
        "# -----------------------------\n",
        "\n",
        "def walk_forward_splits(df, initial_days=365 * 2, horizon_days=90, step_days=90):\n",
        "    \"\"\"Generate train/test splits for walk-forward (rolling-origin) CV.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame with 'ds' sorted ascending.\n",
        "    initial_days : int\n",
        "        Size of the initial training window in days.\n",
        "    horizon_days : int\n",
        "        Forecast horizon (test) window length in days.\n",
        "    step_days : int\n",
        "        How much to move the window each iteration.\n",
        "\n",
        "    Yields\n",
        "    ------\n",
        "    (train_df, test_df)\n",
        "    \"\"\"\n",
        "    df = df.sort_values('ds').reset_index(drop=True)\n",
        "    start = 0\n",
        "    n = len(df)\n",
        "    initial = initial_days\n",
        "    while True:\n",
        "        train_end = start + initial\n",
        "        test_end = train_end + horizon_days\n",
        "        if test_end > n:\n",
        "            break\n",
        "        train_df = df.iloc[:train_end].copy()\n",
        "        test_df = df.iloc[train_end:test_end].copy()\n",
        "        yield train_df, test_df\n",
        "        start += step_days\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3) METRICS\n",
        "# -----------------------------\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    # avoid division by zero\n",
        "    denom = np.where(np.abs(y_true) < 1e-8, 1e-8, np.abs(y_true))\n",
        "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n",
        "\n",
        "\n",
        "def evaluate_forecast(y_true, y_pred):\n",
        "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape_v = mape(y_true, y_pred)\n",
        "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape_v}\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4) BASELINE PROPHET WITH DEFAULT PARAMETERS\n",
        "# -----------------------------\n",
        "\n",
        "def fit_prophet_and_forecast(train_df, periods, freq='D', prophet_kwargs=None):\n",
        "    if prophet_kwargs is None:\n",
        "        prophet_kwargs = {}\n",
        "    m = Prophet(**prophet_kwargs)\n",
        "    m.add_country_holidays(country_name='US')  # optional helpful prior\n",
        "    m.fit(train_df)\n",
        "\n",
        "    future = m.make_future_dataframe(periods=periods, freq=freq)\n",
        "    forecast = m.predict(future)\n",
        "    # keep only forecasted horizon\n",
        "    return m, forecast\n",
        "\n",
        "\n",
        "def baseline_prophet_cv(df, initial_days=365 * 2, horizon_days=90, step_days=90):\n",
        "    \"\"\"Run walk-forward CV with default Prophet and return aggregated metrics.\"\"\"\n",
        "    results = []\n",
        "    for train_df, test_df in walk_forward_splits(df, initial_days, horizon_days, step_days):\n",
        "        model, forecast = fit_prophet_and_forecast(train_df, periods=len(test_df))\n",
        "        # extract forecasted values aligned with test_df\n",
        "        y_pred = forecast.set_index('ds').loc[test_df['ds'], 'yhat'].values\n",
        "        y_true = test_df['y'].values\n",
        "        results.append(evaluate_forecast(y_true, y_pred))\n",
        "    # aggregate\n",
        "    df_res = pd.DataFrame(results)\n",
        "    return df_res.mean().to_dict(), df_res\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5) OPTUNA OPTIMIZATION\n",
        "# -----------------------------\n",
        "\n",
        "def prophet_objective_factory(df, initial_days=365 * 2, horizon_days=90, step_days=90, trials_per_split=1):\n",
        "    \"\"\"Return an Optuna objective function that performs walk-forward CV for a candidate set of hyperparameters.\n",
        "\n",
        "    trials_per_split: normally 1. Kept for future extensions.\n",
        "    \"\"\"\n",
        "    def objective(trial):\n",
        "        # Suggest hyperparameters\n",
        "        changepoint_prior_scale = trial.suggest_loguniform('changepoint_prior_scale', 0.001, 0.5)\n",
        "        seasonality_prior_scale = trial.suggest_loguniform('seasonality_prior_scale', 0.01, 20.0)\n",
        "        seasonality_mode = trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative'])\n",
        "        n_changepoints = trial.suggest_int('n_changepoints', 5, 50)\n",
        "        changepoint_range = trial.suggest_uniform('changepoint_range', 0.7, 0.95)\n",
        "\n",
        "        prophet_kwargs = {\n",
        "            'changepoint_prior_scale': changepoint_prior_scale,\n",
        "            'seasonality_prior_scale': seasonality_prior_scale,\n",
        "            'seasonality_mode': seasonality_mode,\n",
        "            'n_changepoints': n_changepoints,\n",
        "            'changepoint_range': changepoint_range\n",
        "        }\n",
        "\n",
        "        # perform walk-forward CV and get average RMSE across splits\n",
        "        rmses = []\n",
        "        for train_df, test_df in walk_forward_splits(df, initial_days, horizon_days, step_days):\n",
        "            try:\n",
        "                m = Prophet(**prophet_kwargs)\n",
        "                m.add_country_holidays(country_name='US')\n",
        "                m.fit(train_df)\n",
        "                future = m.make_future_dataframe(periods=len(test_df), freq='D')\n",
        "                forecast = m.predict(future)\n",
        "                y_pred = forecast.set_index('ds').loc[test_df['ds'], 'yhat'].values\n",
        "                y_true = test_df['y'].values\n",
        "                rmses.append(math.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "            except Exception as e:\n",
        "                # If training fails, return a large penalty\n",
        "                return 1e6\n",
        "        # objective to minimize\n",
        "        return float(np.mean(rmses))\n",
        "\n",
        "    return objective\n",
        "\n",
        "\n",
        "def run_optuna(df, n_trials=40, direction='minimize', seed=42,\n",
        "               initial_days=365 * 2, horizon_days=90, step_days=90):\n",
        "    study = optuna.create_study(direction=direction, sampler=optuna.samplers.TPESampler(seed=seed))\n",
        "    objective = prophet_objective_factory(df, initial_days, horizon_days, step_days)\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "    return study\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6) FINAL MODEL TRAINING & FORECAST\n",
        "# -----------------------------\n",
        "\n",
        "def train_final_prophet(df_train_full, best_params, periods):\n",
        "    model = Prophet(**best_params)\n",
        "    model.add_country_holidays(country_name='US')\n",
        "    model.fit(df_train_full)\n",
        "    future = model.make_future_dataframe(periods=periods, freq='D')\n",
        "    forecast = model.predict(future)\n",
        "    return model, forecast\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7) COMPARISON BASELINE: EXPONENTIAL SMOOTHING\n",
        "# -----------------------------\n",
        "\n",
        "def exp_smoothing_forecast(train_series, periods):\n",
        "    \"\"\"Fit Holt-Winters Exponential Smoothing and forecast.\n",
        "\n",
        "    train_series : pd.Series indexed by ds\n",
        "    periods : int\n",
        "    \"\"\"\n",
        "    model = ExponentialSmoothing(train_series, seasonal='add', seasonal_periods=365, trend='add')\n",
        "    fit = model.fit(optimized=True)\n",
        "    forecast = fit.forecast(periods)\n",
        "    return forecast\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 8) MAIN EXECUTION\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 1) Generate dataset\n",
        "    df = generate_synthetic_daily(start_date='2016-01-01', end_date='2020-12-31')\n",
        "    print(f\"Generated dataset with {len(df)} daily rows from {df['ds'].min().date()} to {df['ds'].max().date()}\")\n",
        "\n",
        "    # 2) Split into train / held-out test\n",
        "    # We'll hold out the last 180 days for final evaluation\n",
        "    holdout_days = 180\n",
        "    df_train_full = df.iloc[:-holdout_days].copy()\n",
        "    df_holdout = df.iloc[-holdout_days:].copy()\n",
        "    print(f\"Train full length: {len(df_train_full)}, Holdout length: {len(df_holdout)}\")\n",
        "\n",
        "    # 3) Baseline Prophet CV\n",
        "    print(\"Running baseline Prophet CV (this may take several minutes)...\")\n",
        "    baseline_mean_metrics, baseline_all = baseline_prophet_cv(df_train_full,\n",
        "                                                             initial_days=365*2,\n",
        "                                                             horizon_days=90,\n",
        "                                                             step_days=90)\n",
        "    print(\"Baseline CV average metrics:\")\n",
        "    print(baseline_mean_metrics)\n",
        "\n",
        "    # 4) Run Optuna to optimize Prophet hyperparameters\n",
        "    print(\"Running Optuna hyperparameter search (this may take several minutes)...\")\n",
        "    study = run_optuna(df_train_full, n_trials=40, seed=42,\n",
        "                       initial_days=365*2, horizon_days=90, step_days=90)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    print(study.best_trial.params)\n",
        "    best_params = study.best_trial.params\n",
        "\n",
        "    # Map Optuna param names to Prophet kwargs (optuna returns floats; they are fine)\n",
        "    prophet_best_kwargs = {\n",
        "        'changepoint_prior_scale': best_params['changepoint_prior_scale'],\n",
        "        'seasonality_prior_scale': best_params['seasonality_prior_scale'],\n",
        "        'seasonality_mode': best_params['seasonality_mode'],\n",
        "        'n_changepoints': int(best_params['n_changepoints']),\n",
        "        'changepoint_range': best_params['changepoint_range']\n",
        "    }\n",
        "\n",
        "    # 5) Train final optimized Prophet on full train and forecast holdout\n",
        "    print(\"Training final optimized Prophet on full training data...\")\n",
        "    model_opt, forecast_opt = train_final_prophet(df_train_full, prophet_best_kwargs, periods=holdout_days)\n",
        "\n",
        "    # get forecast values corresponding to holdout ds\n",
        "    forecast_values = forecast_opt.set_index('ds').loc[df_holdout['ds']]\n",
        "    y_pred_opt = forecast_values['yhat'].values\n",
        "    y_true = df_holdout['y'].values\n",
        "    opt_metrics = evaluate_forecast(y_true, y_pred_opt)\n",
        "    print(\"Optimized Prophet metrics on holdout:\")\n",
        "    print(opt_metrics)\n",
        "\n",
        "    # 6) Baseline Exponential Smoothing forecast trained on df_train_full and evaluated on holdout\n",
        "    print(\"Training Exponential Smoothing baseline and forecasting holdout...\")\n",
        "    train_series = df_train_full.set_index('ds')['y']\n",
        "    es_forecast = exp_smoothing_forecast(train_series, periods=holdout_days)\n",
        "    # align index\n",
        "    es_forecast = pd.Series(es_forecast.values, index=df_holdout['ds'])\n",
        "    es_metrics = evaluate_forecast(y_true, es_forecast.values)\n",
        "    print(\"Exponential Smoothing metrics on holdout:\")\n",
        "    print(es_metrics)\n",
        "\n",
        "    # 7) Compare CV baseline vs optimized CV\n",
        "    # We'll also compute CV for the best params to compare CV performance\n",
        "    print(\"Running CV for optimized parameters to compare with baseline CV (on training data)...\")\n",
        "    # small function to run CV for specific prophet kwargs\n",
        "    def prophet_cv_with_kwargs(df_input, prophet_kwargs, initial_days=365*2, horizon_days=90, step_days=90):\n",
        "        results = []\n",
        "        for train_df, test_df in walk_forward_splits(df_input, initial_days, horizon_days, step_days):\n",
        "            m = Prophet(**prophet_kwargs)\n",
        "            m.add_country_holidays(country_name='US')\n",
        "            m.fit(train_df)\n",
        "            future = m.make_future_dataframe(periods=len(test_df), freq='D')\n",
        "            forecast = m.predict(future)\n",
        "            y_pred = forecast.set_index('ds').loc[test_df['ds'], 'yhat'].values\n",
        "            y_true = test_df['y'].values\n",
        "            results.append(evaluate_forecast(y_true, y_pred))\n",
        "        df_res = pd.DataFrame(results)\n",
        "        return df_res.mean().to_dict(), df_res\n",
        "\n",
        "    opt_cv_mean_metrics, opt_cv_all = prophet_cv_with_kwargs(df_train_full, prophet_best_kwargs,\n",
        "                                                              initial_days=365*2, horizon_days=90, step_days=90)\n",
        "    print(\"Optimized CV average metrics (training data):\")\n",
        "    print(opt_cv_mean_metrics)\n",
        "\n",
        "    # 8) Save final forecast values chronologically as text\n",
        "    final_forecast_df = pd.DataFrame({\n",
        "        'ds': df_holdout['ds'].values,\n",
        "        'y_true': y_true,\n",
        "        'yhat_optimized': y_pred_opt,\n",
        "        'es_forecast': es_forecast.values\n",
        "    })\n",
        "\n",
        "    out_csv = 'final_holdout_forecasts.csv'\n",
        "    final_forecast_df.to_csv(out_csv, index=False)\n",
        "    print(f\"Final holdout forecasts saved to {out_csv}\")\n",
        "\n",
        "    # 9) Print concise text-based report (summary)\n",
        "    print(\"\\n--- SUMMARY REPORT ---\")\n",
        "    print(\"Hyperparameter search space: changepoint_prior_scale [0.001,0.5] (log-uniform), seasonality_prior_scale [0.01,20] (log-uniform), seasonality_mode {additive,multiplicative}, n_changepoints [5,50] (int), changepoint_range [0.7,0.95] (uniform).\")\n",
        "    print(f\"Best optuna params: {study.best_trial.params}\")\n",
        "    print(\"Baseline CV metrics (averaged across splits):\")\n",
        "    print(baseline_mean_metrics)\n",
        "    print(\"Optimized CV metrics (averaged across splits):\")\n",
        "    print(opt_cv_mean_metrics)\n",
        "    print(\"Holdout comparison on last {0} days:\".format(holdout_days))\n",
        "    print(f\"Optimized Prophet on holdout: {opt_metrics}\")\n",
        "    print(f\"Exponential Smoothing on holdout: {es_metrics}\")\n",
        "\n",
        "    # 10) Optional: save study results\n",
        "    study_df = study.trials_dataframe()\n",
        "    study_df.to_csv('optuna_study_trials.csv', index=False)\n",
        "    print(\"Optuna trial details saved to optuna_study_trials.csv\")\n",
        "\n",
        "    # 11) Display the first 20 forecast rows as chronological text snippet\n",
        "    print(\"\\nFirst 20 rows of final holdout forecasts (chronological):\")\n",
        "    with pd.option_context('display.max_rows', 20, 'display.max_columns', None):\n",
        "        print(final_forecast_df.head(20).to_string(index=False))\n",
        "\n",
        "    # 12) Plot actual vs optimized forecast for holdout\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(df['ds'], df['y'], label='history')\n",
        "        plt.plot(final_forecast_df['ds'], final_forecast_df['yhat_optimized'], label='prophet_optimized_forecast')\n",
        "        plt.plot(final_forecast_df['ds'], final_forecast_df['es_forecast'], label='exp_smoothing_forecast')\n",
        "        plt.axvline(df_holdout['ds'].iloc[0], color='k', linestyle='--', alpha=0.6)\n",
        "        plt.legend()\n",
        "        plt.title('History and holdout forecasts')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('y')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('forecast_comparison.png')\n",
        "        print('Plot saved to forecast_comparison.png')\n",
        "    except Exception as e:\n",
        "        print('Could not create plot:', e)\n",
        "\n",
        "    print('\\nScript finished.')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}